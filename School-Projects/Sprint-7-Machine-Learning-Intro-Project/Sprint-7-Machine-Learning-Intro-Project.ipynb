{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40fffded-895a-4e9e-9c33-1b71f5232774",
   "metadata": {},
   "source": [
    "<div style=\"border:solid blue 2px; padding: 20px\"> \n",
    "\n",
    "<strong>Reviewer's Introduction</strong>\n",
    "\n",
    "Hello Avon! üëã \n",
    "\n",
    "I'm happy to review your project today.\n",
    "\n",
    "I will categorize my comments in green, blue or red boxes like this:\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Success:</b> Everything is done successfully.\n",
    "</div>\n",
    "<div class=\"alert alert-warning\">\n",
    "    <b>Remarks:</b> Suggestions for optimizations or improvements.\n",
    "</div>\n",
    "<div class=\"alert alert-danger\">\n",
    "    <b>Needs fixing:</b> This must be fixed for a project to be approved.\n",
    "</div>\n",
    "\n",
    "Please don't remove my comments :) If you have any questions or comments, don't hesitate to respond to my comments by creating a box that looks like this: \n",
    "<div class=\"alert alert-info\"> <b>Student's comment:</b> Your text here.</div>    \n",
    "<br>\n",
    "\n",
    "\n",
    "üìå Here's how to create code for student comments inside a Markdown cell:\n",
    "    \n",
    "    \n",
    "    <div class=\"alert alert-info\">\n",
    "    <b> Student's comment</b>\n",
    "\n",
    "    Your text here. \n",
    "    </div>\n",
    "\n",
    "You can find out how to **format text** in a Markdown cell or how to **add links** [here](https://sqlbak.com/blog/jupyter-notebook-markdown-cheatsheet). \n",
    "\n",
    "\n",
    "<hr>\n",
    "Reviewer: Han Lee <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630062f9-1140-4c6b-9f5b-f4f012750e68",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: solid blue 2px; padding: 15px; margin: 10px\">\n",
    "\t<b>Reviewer's Comments ‚Äì Iteration 1</b>\n",
    "\n",
    "Congratulations! \n",
    "\n",
    "This project meets all requirements ‚úÖ, and is approved. üéâ\n",
    "\n",
    "\n",
    "<b>Notable strengths:</b>  \n",
    "\n",
    "‚úîÔ∏è Clear understanding of splitting dataset \n",
    "\n",
    "‚úîÔ∏è Use of baseline to compare against multiple models  \n",
    "\n",
    "‚úîÔ∏è Use of custom hyperparameter tuning \n",
    "\n",
    "‚úîÔ∏è Concise and informative conclusion\n",
    "\n",
    "Well done on your first machine learning project! You will continue to use these techniques in future sprints. Keep up the great work.\n",
    "\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01a2362-f027-4abd-b846-4eca2d1bf6e8",
   "metadata": {},
   "source": [
    "***known***\n",
    "- data contains only new plan subscribers\n",
    "- preprocessing done\n",
    "- binary classification\n",
    "- 3214 rows * 5 columns\n",
    "- target = ['is_ultra']\n",
    "- features = ['calls', 'minutes', 'messages', 'mb_used']\n",
    "- 3:1:1 / 60%:20%:20% / train:valid:test - no external test set\n",
    "- .75 accuracy threshold\n",
    "\n",
    "***unknown***\n",
    "- which model to use?\n",
    "- hyperparameters?\n",
    "- findings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce5fa335-5c96-4903-9bec-aefba432a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # decision tree\n",
    "from sklearn.ensemble import RandomForestClassifier # random forest\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression\n",
    "\n",
    "from sklearn.model_selection import train_test_split # train:valid:test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe75ff-5bc1-4567-88f9-b0b5e9a55ed5",
   "metadata": {},
   "source": [
    "**creating a dataframe with the given .csv file, checking for any immediately observable trends**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c7b37b0-a48a-4ee9-84f9-9916cab4a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/users_behavior.csv') \n",
    "\n",
    "#data.info()\n",
    "#data.shape\n",
    "#print(data.duplicated().sum())\n",
    "#print(data.sample(17, random_state=12345))\n",
    "#print(data[data['is_ultra'] == 1].sort_values(by='minutes'))\n",
    "#print(data[data['is_ultra'] == 0].sort_values(by='minutes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bedaf163-4df5-478e-ab44-f2add5bb61d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ultra = data[data['is_ultra'] == 1]\n",
    "#smart = data[data['is_ultra'] == 0]\n",
    "\n",
    "#display(ultra.describe())\n",
    "#display(smart.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efffc964-3259-4ef2-9208-dbf96f1caa8a",
   "metadata": {},
   "source": [
    "**There are no immediately obvious differences in the two plans regarding user behavior, with 'Ultra' having over twice the amount of subscribers compared to 'Smart'. 2229 to 985 respectively.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf81e7-e4a4-483f-a19c-70aa7c4cdcc4",
   "metadata": {},
   "source": [
    "**Ultra ranges**\n",
    "- Calls: (0, 244)\n",
    "- Minutes: (0, 1632)\n",
    "- Messages: (0, 224)\n",
    "- MB Used: (0, 49745.73)\n",
    "\n",
    "**Smart ranges**\n",
    "- Calls: (0, 198)\n",
    "- Minutes: (0, 1390)\n",
    "- Messages: (0, 143)\n",
    "- MB Used: (0, 38552.62)\n",
    "\n",
    "***Ultra subscribers make up 69.35% of our dataset***\n",
    "\n",
    "***Smart subscribers make up 30.65% of our dataset***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dae1a28-e3fb-41a5-9f27-a6d831a01644",
   "metadata": {},
   "source": [
    "**Assigning features & target, splitting our data into 3 sets for training, validation, and testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57b7d345-7431-464b-9157-c25ed294418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning features and target\n",
    "features = data.drop('is_ultra', axis = 1)\n",
    "target = data['is_ultra']\n",
    "\n",
    "# splitting the data into training/temporary (temp for 2nd split) sets 60%/40%\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(features, target, test_size = .4, random_state = 12345)\n",
    "\n",
    "# splitting our temporary set (remaining 40%), into validation/test sets 20%/20%\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_temp, target_temp, test_size = .5, random_state = 12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a03cc8b-0d86-4ee8-be64-4c8eaf30e3e6",
   "metadata": {},
   "source": [
    "**double checking ratio after split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66716800-8958-4550-828a-26f28aca80ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 59.98755444928439%\n",
      "Validation set size: 20.00622277535781%\n",
      "Test set size: 20.00622277535781%"
     ]
    }
   ],
   "source": [
    "print('Training set size:', (len(features_train)/len(data))*100, end='%')\n",
    "print()\n",
    "print('Validation set size:', (len(features_valid)/len(data))*100, end='%')\n",
    "print()\n",
    "print('Test set size:', (len(features_test)/len(data))*100, end='%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8a87d3-1b89-469c-be6a-b36224b43c40",
   "metadata": {},
   "source": [
    "**triple checking for unique entries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f4bd438-f2ef-4ba6-99e2-6c1a6b9bd046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(features_train.head())\n",
    "#print(features_valid.head())\n",
    "#print(features_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec9a53-accb-4735-aedd-0b3ffaebf82c",
   "metadata": {},
   "source": [
    "***DecisionTreeClassifier - Training on a depth range of (1, 11) exclusive***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4648a5cd-7fba-4914-a8e5-96f9e1a6c4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of best model on validation set (depth = 3): 0.7853810264385692\n"
     ]
    }
   ],
   "source": [
    "best_score_tree = 0\n",
    "best_model_depth = 0\n",
    "for depth in range(1,11):\n",
    "    model = DecisionTreeClassifier(random_state = 12345, max_depth = depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    score = model.score(features_valid, target_valid)\n",
    "    if score > best_score_tree:\n",
    "        best_score_tree = score\n",
    "        best_model_depth = depth\n",
    "\n",
    "print('Accuracy of best model on validation set (depth = {}): {}'.format(best_model_depth, best_score_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606ec05-888c-46d1-a5fa-d802e0252970",
   "metadata": {},
   "source": [
    "**A depth value of 3 yielded us the most accurate model with a 78.53% accuracy rating on the validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f8e293-65d8-411e-9f00-5c9b79d56cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of final model on test set: 77.91601866251943%"
     ]
    }
   ],
   "source": [
    "final_tree_model = DecisionTreeClassifier(random_state = 12345, max_depth = 3)\n",
    "final_tree_model.fit(features_train, target_train)\n",
    "\n",
    "test_score = final_tree_model.score(features_test, target_test)\n",
    "print('Accuracy of final model on test set:', test_score*100, end = '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e186ad78-124d-41c9-9bf6-974847b4bc48",
   "metadata": {},
   "source": [
    "**After utilizing a depth value of 3, our model has score a 77.92% accuracy rating against our test set, scoring slighlty higher than our desired threshold of 75%**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db4e1bc-bad4-449f-8d2f-798a683ab4ab",
   "metadata": {},
   "source": [
    "***RandomForestClassifier - Training on an n_estimator range of (10, 51) exclusive, by increments of 10, with tree depth ranges of (1,11) exclusive, for a total of 50 hyperparameter combinations***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f14bf525-10f2-49f5-ae66-8799acdd3649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of best model on validation set (depth = 8, est = 40): 80.87091757387248%"
     ]
    }
   ],
   "source": [
    "best_score_forest = 0\n",
    "best_model_depth = 0\n",
    "best_model_est = 0\n",
    "for est in range(10, 51, 10):\n",
    "    for depth in range(1, 11):\n",
    "        model = RandomForestClassifier(random_state = 12345, n_estimators = est, max_depth = depth)\n",
    "        model.fit(features_train, target_train)\n",
    "        score = model.score(features_valid, target_valid)\n",
    "        if score > best_score_forest:\n",
    "            best_score_forest = score\n",
    "            best_model_depth = depth\n",
    "            best_model_est = est\n",
    "\n",
    "print('Accuracy of best model on validation set (depth = {}, est = {}): {}'.format(best_model_depth, best_model_est, best_score_forest*100), end = '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc75d9e9-b48c-4344-aacd-7b09dada6e33",
   "metadata": {},
   "source": [
    "**A max_depth of 8, and n_estimator of 40 yields us the best model, with an accuracy value of 80.87%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dee49aa1-5b1e-408e-85ad-917e1d25c8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of final model on test set: 79.62674961119751%"
     ]
    }
   ],
   "source": [
    "final_forest_model = RandomForestClassifier(random_state = 12345, n_estimators = 40, max_depth = 8)\n",
    "final_forest_model.fit(features_train, target_train)\n",
    "\n",
    "test_score = final_forest_model.score(features_test, target_test)\n",
    "print('Accuracy of final model on test set:', test_score*100, end = '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d442ebf-e656-473a-9e56-404a51d514f9",
   "metadata": {},
   "source": [
    "**Creating a final model using our optimal hyperparameters, the model scored a 79.63% accuracy rating against our test set. Slightly lower than our score against the validation set, but performing better than our DecisionTreeClassifier model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516acf56-55b4-46bd-8ed3-5986c321a423",
   "metadata": {},
   "source": [
    "***LogisticRegression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e3bc9dd-0bde-495e-becb-12d01636392b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model on training set: 71.57676348547717%\n",
      "Accuracy of model on valid set: 70.91757387247279%\n",
      "Accuracy of model on test set: 68.89580093312597%"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(random_state = 12345, solver = 'liblinear')\n",
    "log_model.fit(features_train, target_train)\n",
    "log_score_train = log_model.score(features_train, target_train)\n",
    "log_score_valid = log_model.score(features_valid, target_valid)\n",
    "log_score_test = log_model.score(features_test, target_test)\n",
    "\n",
    "print('Accuracy of model on training set:', log_score_train*100, end = '%')\n",
    "print()\n",
    "print('Accuracy of model on valid set:', log_score_valid*100, end = '%')\n",
    "print()\n",
    "print('Accuracy of model on test set:', log_score_test*100, end = '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb5611f-1c62-4c9c-ba12-659ee47d6d07",
   "metadata": {},
   "source": [
    "***Final Models and their Accuracy rating against the Test Set:***\n",
    "\n",
    "**DecisionTreeClassifier: 77.92%**\n",
    "\n",
    "**RandomForestClassifier: 79.63%**\n",
    "\n",
    "**LogisticRegression: 68.89%**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13139df6-841e-4627-9e88-aecad970ae4f",
   "metadata": {},
   "source": [
    "***After training our different models, RandomForestClassifier gave us the best results when predicting the 'is_ultra' column on our test set, which is 'new data' from the perspective of our trained model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e028a4d5-f06e-4cff-a021-c4535515fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model with hyperparameters:\n",
    "\n",
    "final_model = RandomForestClassifier(random_state = 12345, n_estimators = 40, max_depth = 8)\n",
    "final_model.fit(features_train, target_train)\n",
    "\n",
    "final_score = final_model.score(features_test, target_test)\n",
    "\n",
    "#print(final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3adb68b-a343-4522-8bc8-2da3c7515079",
   "metadata": {},
   "source": [
    "**Performing Sanity Testing on our final model: Naive Baseline Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fb3f66b-42a8-4e26-96f3-c0c9065a59e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive baseline accuracy of test set: 68.42923794712286%\n",
      "Accuracy of our model against the test set: 79.62674961119751%"
     ]
    }
   ],
   "source": [
    "#print((target_test == 0).sum())\n",
    "#print((target_test == 1).sum())\n",
    "most_frequent = target_test.mode()[0]\n",
    "baseline_accuracy = (target_test == most_frequent).sum() / len(target_test)\n",
    "\n",
    "print('Naive baseline accuracy of test set:', baseline_accuracy*100, end = '%')\n",
    "print()\n",
    "print('Accuracy of our model against the test set:', final_score*100, end = '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7bff6b-b328-41b7-ba42-3537986556c1",
   "metadata": {},
   "source": [
    "***Conclusion***\n",
    "\n",
    "**Best Performing Model & Hyperparameters:**\n",
    "\n",
    "**RandomForestClassifier, Depth = 8, Estimators = 40**\n",
    "\n",
    "**Accuracy rating against test set: 79.63%**\n",
    "\n",
    "**This value passes our expected accuracy threshold of .75, or 75%, and beats the naive baseline accuracy of 68.43%**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
