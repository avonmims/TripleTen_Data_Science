{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f81471",
   "metadata": {},
   "source": [
    "***KNOWN***\n",
    "\n",
    "// general info\n",
    "\n",
    "- Binary Classification Task\n",
    "- features = ['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "- target = ['Exited']\n",
    "- no external test set: 3:1:1 - training:valid:test - 60%:20%:20%\n",
    "\n",
    "// feature types\n",
    "\n",
    "- Categorical Features: ['Surname', 'Geography', 'Gender']\n",
    "- Numerical Features: ['RowNumber', 'CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "- Target is Numerical\n",
    "\n",
    "// misc observations\n",
    "\n",
    "- Tenure column has 9091 / 10000 entries (-909) (1.1% missing)\n",
    "- Surname column contains entries with special characters: data['Surname'][9] = 'H?'\n",
    "- no duplicate CustomerId, 10000 different customers\n",
    "- 'IsActiveMemeber' not mutually exclusive with 'Exited'\n",
    "\n",
    "// class balance\n",
    "\n",
    "- 79.63% of customers have exited ('Exited' == 1)\n",
    "- 20.37% of customers have not exited ('Exited' == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2067ce17",
   "metadata": {},
   "source": [
    "***UNKNOWN***\n",
    "- model type? DecisionTreeClassifier, RandomForestClassifier, LogisticRegression\n",
    "- hyperparameters?\n",
    "- class balancing methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc211193",
   "metadata": {},
   "source": [
    "***OBJECTIVES***\n",
    "- F1 score: 0.59 against test set\n",
    "- Plot ROC and measure AUC-ROC\n",
    "- methods of balance to try: upsampling & class_weight='balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc55f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Churn.csv')\n",
    "\n",
    "#print(data.dtypes)\n",
    "#data.info(verbose=True)\n",
    "#display(data.head(10))\n",
    "#print(data['Surname'][9])\n",
    "#print(data.isna().sum())\n",
    "#print(data['CustomerId'].duplicated().sum())\n",
    "#print(data['Surname'].value_counts())\n",
    "#print(data[data['Surname'] == 'Smith'])\n",
    "#print(data.duplicated(subset='CustomerId').value_counts())\n",
    "#print(data[data['Tenure'].isna()])\n",
    "#print(data[(data['Tenure'] > 0) & (data['Tenure'] < 1)])\n",
    "#print(data[(data['Tenure'] < 1)])\n",
    "#print(data['Geography'].value_counts())\n",
    "\n",
    "data['Tenure_Missing'] = data['Tenure'].isnull().astype(int)\n",
    "data['Tenure'] = data['Tenure'].fillna(0)\n",
    "#print(data[data['Tenure_Missing'] == 1])\n",
    "#print(data.info(verbose=True))\n",
    "\n",
    "#print(data['Exited'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c56835b",
   "metadata": {},
   "source": [
    "***data analysis & cleaning, adding surface-level observations to known & unknown***\n",
    "\n",
    "**We've done away with the missing values within the 'Tenure' column, replacing them with 0. Seeing as though 'Tenure' is measured in years, and only whole numbers, if there exists a customer with 11 months of loan history, are they rounded up to 1.0? or do they remain at 0.0? Or could the missing values have different implications on a per observation basis? Human error, new customer, bank system glitch, or has no active loan?**\n",
    "\n",
    "**In any case, I've decided to create a new column that saves the instances of 'Tenure' == NaN, as 'Tenure_Missing'**\n",
    "\n",
    "**Class balance is 79.63% negative, 20.37% positive. We NEED to consider this when training our model later, as predicting positive for every observation would yield a ~80% accuracy rating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "959f9c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# since our categorical entries are nominal, we will use OHE to prepare them\n",
    "data_ohe = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# separate features from target\n",
    "features = data_ohe.drop('Exited', axis=1)\n",
    "target = data_ohe['Exited']\n",
    "\n",
    "# 60% train set, 40% temporary set\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(features, target, test_size=.4, random_state=12345)\n",
    "\n",
    "# 20% valid set, 20% test set\n",
    "features_valid , features_test, target_valid, target_test = train_test_split(features_temp, target_temp, test_size=.5, random_state=12345)\n",
    "\n",
    "# specify numeric features\n",
    "numeric = ['RowNumber', 'CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "\n",
    "# tune scaler to training data features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "\n",
    "# apply scaling to numeric columns in our feature sets\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])\n",
    "\n",
    "#print(features_train.head())\n",
    "#print(features_valid.head())\n",
    "#print(features_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f97f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
